---
layout: about
title: About
permalink: /
subtitle:

profile:
  align: right
  image: UMich_Yichi.jpg
  image_circular: true # crops the image to make it circular
  more_info:

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

Hello! My name is Yichi Zhang, and I am doing multimodal research at Bytedance Seed. I got my Ph.D. in Computer Science and Engineering at the University of Michigan, advised by Professor [Joyce Chai](https://web.eecs.umich.edu/~chaijy/) as a member of the [SLED lab](https://sled.eecs.umich.edu/). I am broadly interested in the intersection between conversational and perceptual AI research, with a particular focus on real-time interactive systems, language grounding to visual and physical contexts， multi-modal dialog, and embodied AI. I have won the [1st Amazon Alexa Prize SimBot Challenge](https://www.amazon.science/alexa-prize/simbot-challenge) in 2023 as the team leader of [SEAGULL](https://www.amazon.science/alexa-prize/university-of-michigans-seagull-wins-alexa-prize-simbot-challenge). Before joining UMich, I obtained my Master’s in Information and Communication Engineering at Tsinghua University in 2020, advised by Professor [Zhijian Ou](http://oa.ee.tsinghua.edu.cn/ouzhijian/). In 2019, I worked with Professor [Zhou Yu](https://www.cs.columbia.edu/~zhouyu/) as a visiting scholar on task-oriented dialog systems. I got my Bachelor’s in Electronic Information Science and Technology from Tsinghua University in 2017. 
